% arara: pdflatex: { shell: yes }
% arara: pythontex: {verbose: yes, rerun: modified }
% arara: pdflatex: { shell: yes }
% arara: move: {  files: ['chapter7.pdf'], target: ['..'] }


\input{header}


\chapter{Chapter 7: Exercises and remarks}
\label{cha:questions-chapter-7}



\input{bh-7.1.tex}

\section{Section 7.2}
\label{sec:section-7.2}


\begin{exercise}
BH.7.2.2. Write down the integral to compute $\E{(X-Y)^{2}}$, and solve it.
\begin{solution}
We have
\begin{align}
    \E{(X-Y)^2} &= \int_{-\infty}^\infty \int_{-\infty}^\infty (x - y)^2 f_{X,Y}(x,y) \d x \d y \\
    &=\int_0^1 \int_0^1 (x - y)^2 \d x \d y \\
    &=\int_0^1 \int_0^1 (x^{2} - 2 x y +  y^2) \d x \d y \\
    &=\int_0^1 \int_0^1 x^{2} \d x \d y
    -2\int_0^1 \int_0^1  x y  \d x \d y
    +\int_0^1 \int_0^1  y^2 \d x \d y  \\
    &=\int_0^1 x^{2} \d x
    -2\int_0^1 \int_0^1 x y  \d x \d y
    + \int_0^1  y^2  \d y \\
    &=1/3  -2 \cdot 1/ 2 \cdot 1/ 2 + 1/3.
\end{align}
\end{solution}
\end{exercise}


\begin{exercise}
Explain that for a continuous r.v. $X$ with CDF $F$ and $a$ and $b$ (so it might be that $a>b$),
\begin{equation}
  \label{eq:87}
\P{a< X < b} = [F(b) - F(a)]^{+}.
\end{equation}
\begin{hint}
  Recall that $F\in [0, 1]$.
\end{hint}
\begin{solution}
\begin{align}
a<b & \implies \P{a< X < b} = F(b) - F(a) = [F(b) - F(a)]^{+} \\
a\geq b & \implies \P{a< X < b} =  0 = [F(b) - F(a)]^{+},
\end{align}
where the last equality follows from the fact that $F$ is increasing.
\end{solution}
\end{exercise}

\begin{remark}
If you are like me, you underestimate at first the importance of using indicator functions. In fact, they are extremely useful for several reasons.
\begin{enumerate}
\item  They help to keep your formulas clean.
\item You can use them in computer code as logical conditions, or to help counting relevant events, something you need when numerically estimating multi-D integrals,  for machine learning for instance.
\item  Even though figures give geometrical insight into how to integrate over an 2D area, when it comes to reversing the sequence of integration, indicators are often easier to use.
\item In fact, \emph{expectation is the fundamental concept in probability theory}, and the \emph{probability of an event is defined} as
\begin{equation}
  \label{eq:84}
  \P{A} := \E{\1{A}}.
\end{equation}
Thus, the fundamental bridge is actually an application of LOTUS to indicator functions. Hence, reread BH.4.4!
\end{enumerate}
\end{remark}

\begin{exercise}
What is $\int_{-\infty}^{\infty} \1{0\leq x \leq 3} \d x$?
\begin{solution}
\begin{align*}
\int_{-\infty}^{\infty} \1{0\leq x \leq 3} \d x =\int_{0}^{3}  \d x  = 3.
\end{align*}
\end{solution}
\end{exercise}

\begin{exercise}
What is
\begin{equation}
\label{eq:85}
\int x \1{0\leq x \leq 4} \d x?
\end{equation}
\begin{solution}
\begin{align*}
\int x \1{0\leq x \leq 4} \d x  = \int_{0}^{4} x \d x = 16/2 = 8.
\end{align*}
\end{solution}
\end{exercise}

When we do an integral over a 2D surface we can first integrate over the $x$ and then over the $y$, or the other way around, whatever is the most convenient.
(There are conditions about how to handle multi-D integral, but for this course these are irrelevant.)

\begin{exercise}
What is
\begin{equation}
\label{eq:185}
\iint x y \1{0\leq x \leq 3}\1{0\leq y \leq 4} \d x \d y?
\end{equation}
\begin{solution}
\begin{align*}
\iint xy \1{0\leq x \leq 3}\1{0\leq y \leq 4} \d x \d y
&=\int_{0}^{3} x \int_{0}^{4} y \d y \d x\\
&=\int_{0}^{3} x \frac{y^{2}} 2 \biggr|_{0}^{4} \d x\\
&= \int_{0}^{3} x\cdot 8 \d x = 8\cdot 9/2 = 4\cdot 9.
\end{align*}
\end{solution}
\end{exercise}

\begin{exercise}
What is
\begin{align}
\label{eq:285}
\iint \1{0\leq x \leq 3} \1{0\leq y \leq 4}\1{x\leq y}\d x \d y?
\end{align}
\begin{solution}
Two solutions. First we integrate over $y$.
\begin{align}
\label{eq:385}
\iint \1{0\leq x \leq 3} \1{0\leq y \leq 4}\1{x\leq y}\d x \d y
&=\int \1{0\leq x \leq 3} \int \1{0\leq y \leq 4}\1{x\leq y}\d y \d x\\
&=\int \1{0\leq x \leq 3} \int \1{\max\{x, 0\} \leq y \leq 4}\d y \d x\\
&=\int_{0}^{3} \int_{\max\{x, 0\}}^{4}\d y \d x\\
&=\int_{0}^{3} y\biggr|_{\max\{x, 0\}}^{4} \d x\\
&=\int_{0}^{3}  (4-\max\{x, 0\}) \d x\\
&=12 - \int_{0}^{3} \max\{x, 0\} \d x\\
&=12 - \int_{0}^{3} x  \d x\\
&=12 - 9/2.
\end{align}

Let's now instead first integrate over $x$.
\begin{align}
\label{eq:485}
\iint \1{0\leq x \leq 3} \1{0\leq y \leq 4}\1{x\leq y}\d x \d y
&= \int \1{0\leq y \leq 4} \int \1{0\leq x \leq 3} \1{x\leq y}\d x \d y\\
&= \int_{0}^{4} \int \1{0\leq x \leq \min\{3, y\}}\d x \d y\\
&= \int_{0}^{4} \int_{0}^{\min\{3, y\}} \d x \d y\\
&= \int_{0}^{4} \min\{3, y\}\d y\\
&= \int_{0}^{3} \min\{3, y\}\d y + \int_{3}^{4} \min\{3, y\}\d y\\
&= \int_{0}^{3} y \d y + \int_{3}^{4}  3\d y\\
&= 9/2 + 3.
\end{align}
\end{solution}
\end{exercise}


\begin{exercise}\label{ex:2a}
Take $X\sim\Unif{[1,3]}, Y\sim\Unif{[2,4]}$ and independent. Compute
\begin{equation}
  \label{eq:824}
\P{Y\leq 2X}.
\end{equation}
\begin{solution}
Take $c$ the normalization constant (why is $c=1/4$), then using the previous exercise
\begin{align}
\P{Y\leq 2X}
&=\E{\1{Y\leq 2X}} \\
&=c \int_{1}^{3}\int_{2}^{4} \1{y\leq 2x} \d y \d x \\
&=c \int_{1}^{3}\int \1{2\leq y\leq \min\{4,2x\}}  \d y \d x \\
&=c \int_{1}^{3} (\min\{4, 2x\} -2) \d x
\end{align}
Now make a drawing of the function $(\min\{4, 2x\} - 2)$ on the interval $[1,3]$ to see that
\begin{equation}
\int_{1}^{3} (min\{4, 2x\} -2) \d x = \int_{1}^{2} (2x -2) \d x + \int_{2}^{3} (4 -2) \d x.
\end{equation}
I leave the rest of the computation to you.
\end{solution}
\end{exercise}



\section{Section 7.3}
\label{sec:section-7.3}



\begin{exercise}
Give a brief example of a situation where it might be more convenient to employ the correlation than the covariance.  Explain why.
\begin{solution}
The covariance might be a large number, which may  suggest that the rvs $X$ and $Y$ are `very' dependent. However, when $\V X$ and $\V Y$ are also large, the correlation can be small. Thus, correlation is a scaled type of covariance.
\end{solution}
\end{exercise}

\begin{exercise}
In queueing theory  the concept of squared coefficient of variance $SCV$ of a rv $X$ is very important. It is defined as $C = \V{X}/(\E X)^{2}$. Is the SCV of $X$ equal to $\text{Corr}(X,X)$? Can it happen that $C>1$?
\begin{solution}
Answers: no and yes.

We have
\begin{align}
    C = \frac{\V{X}}{(\E{X})^2},
\end{align}
which does not equal
\begin{align}
    \text{Corr}(X,X) = \frac{\cov{X,X}}{\sqrt{\V{X}\V{X}}} = 1
\end{align}
in general (for instance, consider a degenerate random variable $X \equiv 1$). Next, consider a $N(1,100)$ random variable. Then,
\begin{align}
    C = 100/(1^2) = 100 > 1.
\end{align}
\end{solution}
\end{exercise}


\begin{exercise}
Prove the key properties 1--5 of the covariance below BH.7.3.2.
\begin{solution}
\begin{enumerate}
    \item We have
    \begin{align}
        \cov{X,X} = \E{XX} - \E{X}\E{X} = \E{X^2} - \E{X}^2 = \V{X}.
    \end{align}
    \item We have
    \begin{align}
        \cov{X,Y} = \E{XY} - \E{X}\E{Y} = \E{YX} - \E{Y} \E{X} = \cov{Y, X}.
    \end{align}
    \item We have
    \begin{align}
        \cov{X,c} = \E{Xc} - \E{X}\E{c} = c\E{X} - c\E{X} = 0.
    \end{align}
    \item We have
    \begin{align}
        \cov{aX,Y} = \E{aXY} - \E{aX}\E{Y} = a\big(\E{XY} - \E{X}\E{Y}\big) = a\cov{X,Y}.
    \end{align}
    \item We have
    \begin{align}
        \cov{X+Y, Z} &= \E{(X + Y)Z} - \E{X+Y}\E{Z} \\
        &= \E{XZ + YZ} - \big(\E{X} + \E{Y}\big) \E{Z}\\
        &= \E{XZ} - \E{X}\E{Z} + \E{YZ} - \E{Y}\E{Z} \\
        &= \cov{X,Z} + \cov{Y,Z}.
    \end{align}
\end{enumerate}
\end{solution}
\end{exercise}

\begin{exercise}
Using the definition of Covariance (BH.7.3.1) derive the expression $\cov{X,Y}=\E{XY}-\E{X}\E{Y}$. Use this to show why independence of X and Y implies their uncorrelatedness (Note that the converse does not hold).
\begin{solution}
We have
\begin{align}
    \cov{X,Y} &= \E{(X - \E{X})(Y - \E{Y})} \\
    &= \E{XY - X\E{Y} - Y\E{X} + \E{X}\E{Y}} \\
    &= \E{XY} - \E{X}\E{Y} - \E{Y} \E{X} + \E{X}\E{Y}\\
    &= \E{XY}-\E{X}\E{Y}.
\end{align}
When $X$ and $Y$ are independent, then $\E{XY} = \E X \E Y$, and then $\cov{X,Y}=0$.
\end{solution}
\end{exercise}

\begin{exercise}
Let $U, V$ be two rvs and let $a,b\in \R$.
Use the previous question to express $\cov{a(U+V), b(U-V)}$ in terms of $\V{U}$, $\V{V}$ and $\cov{U,V}$.
\begin{solution}
By linearity of the covariance wea have
\begin{align}
    \cov{a(U+V), b(U-V)} &= a \Big( \cov{U, b(U-V)} + \cov{V, b(U-V)} \Big) \\
    &= a \Big( b\big( \cov{U, U} - \cov{U, V} \big)  + b\big( \cov{V, U} - \cov{V,V} \Big) \\
    &= a \Big( b\big( \cov{U, U} - \cov{U, V} \big)  + b\big( \cov{V, U} - \cov{V,V} \Big) \\
    &= a b \Big( \V{U} - \cov{U, V} + \cov{V, U} - \V{V} \Big) \\
    &= a b \Big( \V{U} - \V{V} \Big).
\end{align}
Alternatively one can also use the result from BH.7.1.26, according to which $\cov{X,Y} = \E{XY}-\E{X}\E{Y}$.
\end{solution}
\end{exercise}


\begin{exercise}\label{ex:3a}
The solution of BH.7.3.6 is a somewhat tricky; I would have not  found this trick myself. Here is an approach that is trick free.

Neglecting the event $\{X=Y\}$ as this has zero probability, we know that $M=X, L=Y$ or $M=Y, L=X$. Use this idea and the formula $\cov{M,L} = \E{ML} - \E M \E L$ to derive the result of this example.
\begin{hint}
Realize that $\E{ML} = \E{XY}$.
\end{hint}
\begin{solution}
With the hint: $\E{XY}=1/\lambda^{2}$, when $X, Y \sim\Exp{\lambda}$. Then, $L\sim \Exp{2\lambda}$, since $f_{L}(x) = 2 f_X(x) (1-F_Y(x)) = 2 \lambda e^{-2\lambda x}$. Therefore, $\E L = 1/2\lambda$. Also, by memoryless, $\E{M} = \E L + \E X = 3/2\lambda$. Hence, $\E{M}\E L = 3/4\lambda^{2}$. Hence, $\E{ML}- \E M \E L = 1/\lambda^{2-} 3/4\lambda^2 = 1/4\lambda^{2}$.
\end{solution}
\end{exercise}



\section{Section 7.4}
\label{sec:section-7.4}


\begin{exercise}
Come up with a short illustrative example in which the random vector $\mathbf{X} = (X_1, \ldots, X_6)$ follows a Multinomial Distribution with parameters  $n=10$ and $\mathbf{p}=(\frac{1}{6}, ..., \frac{1}{6}) \in \R^{6}$.
\begin{solution}
We throw 10 fair dice. $X_i$ denotes the number of dice that show the number $i$, $i=1,\ldots,6$.
\end{solution}
\end{exercise}


\section{Section 7.5}



\begin{exercise}
Is the following claim correct? If the rvs $X, Y$ are both normally distributed, then $(X, Y)$ follows a Bivariate Normal distribution.
\begin{solution}
No, this does not always hold, see BH.7.5.2. However, it does hold when $X$ and $Y$ are independent.
\end{solution}
\end{exercise}
\begin{exercise}
Let $X, Y, Z$ be iid $\mathcal{N}(0,1).$ Determine whether or not the random vector
\begin{align*}
    \mathbf{W} = (X+2Y, 3X+4Z, 5Y+6Z, 2X-4Y+Z, X-9Z, 12X+\sqrt{3}Y -\pi Z + 18)
\end{align*}
is Multivariate Normal. (Explain in words, don't do a lot of tedious math here!)
\begin{solution}
Since $X,Y,Z$ are independent normally distributed variables, $(X,Y,Z)$ is multivariate normally distributed. Hence, every linear combination of $X,Y,Z$ is normally distributed. Note that every linear combination of the elements of $W$ can be written as a linear combination of $X,Y,Z$. Hence, every linear combination of the elements of $W$ is normally distributed. Hence, $W$ is multivariate normally distributed.
\end{solution}
\end{exercise}



\input{trailer}
