% arara: pdflatex: { shell: yes }
% arara: pythontex: {verbose: yes, rerun: modified }
% arara: pdflatex: { shell: yes }
% arara: move: {  files: ['chapter9.pdf'], target: ['..'] }

\input{header.tex}


\chapter{Chapter 9: Exercises and remarks}

\section{Section 9.1}

\begin{remark}
Skip BH.9.1.6.
\end{remark}

\begin{exercise}
BH.9.1.7. We will also simulate this in an assignment.

I  like this example as it  shows how to make optimal decisions under uncertainty, but I have to admit that I don't understand the reasoning, or the use of conditional probability to solve this problem. Here is how I would solve the problem.
\begin{enumerate}
\item Explain that $W=(V-b)\1{b \geq \alpha V}$, with $\alpha=2/3$, is the rv that models our payoff.
\item Why is this wrong: $\E W = \E{(V-b)\1{b \geq \alpha V}} = V \E{\1{b \geq \alpha V}} -b \E{\1{b \geq \alpha V}}$?
\item Compute $\E W$, and provide a bound on $\alpha$ to ensure that $\E W > 0$.
\end{enumerate}
\begin{solution}
\begin{enumerate}
  \item The indicator function is zero when the bid is rejected, hence there is a zero payoff. When the bid is accepted the indicator function is one and the resulting payoff is $V-b$, i.e., the prize value minus the offer.
  \item $V$ is a rv, hence cannot be taken out the expectation.
  \item Since $W$ is a function of $V$ we can apply LOTUS and find the expectation by integration. First we assume $b/\alpha < 1$.
\end{enumerate}
\begin{align*}
\E W &= \int_0^1 (v-b) \1{b\geq \alpha v} \d v = \int_0^{b/\alpha} v \d v - b \int_0^{b/\alpha}  \d v \\
  &= b^2/2\alpha^2 - b^2/\alpha = \frac{b^{2}}{\alpha^{2}} \frac{1-2\alpha}{2}.
\end{align*}
Clearly, we need to assume $\alpha<1/2$ to ensure that $\E W > 0$.

Next, assume that $b>\alpha$. Then the expected payout is $\E{W} = 1/2 -b $, as any bid is accepted (why?). Thus, if $b<1/2$ the expected payout is positive. But we assumed that $b>\alpha$, hence $\alpha < b < 1/2$, so again $\alpha<1/2$ for a positive payout.
\end{solution}
\end{exercise}

\begin{exercise}
  BH.9.1.7. continued. By the previous exercise, we know that only when $\alpha<1/2$ we should participate in the game. In other words, when our bid $b$ should be larger than $\alpha V$ to be accepted. If we know $\alpha$, what would be our optimal bid $b$?
\begin{solution}
  When $\alpha < 1/2$ the expected payoff is positive so it becomes interesting. We can write the total payout as:
 \begin{align*}
   \E W &= (1/2 - b) \1{b>\alpha} + \frac{1-2\alpha}{2\alpha^2}b^2 \1{b\leq \alpha}\\
  \end{align*}
  Assume $0<\alpha<1/2$. The expected payoff is a piecewise continuous function since $\lim_{b\uparrow \alpha} \E W  = 1/2 - \alpha = \lim_{b\downarrow \alpha} \E W$.
Now, the left term in the RHS of the equation above, i.e., $(1/2 - b)\1{b>\alpha}$, decreases strictly for $b>\alpha$, while in the right term $b^{2}$ increases strictly for $b<\alpha$. Hence, $\E W$ achieves its maximum for $b=\alpha$.
Therefore, the optimal betting amount is $\alpha$ and results in an expected payoff of $1/2 - \alpha$.
\end{solution}
\end{exercise}

\begin{exercise}
BH.9.1.8. Apply the same type of argumentation to find $\E X$ when $X\sim \FS{p}$.
\begin{solution}
$\E X = 1 + q\E X$, because we have to throw at least once, and with probability $q$, we start again. Hence, $\E X = 1/(1-q) = 1/p$.
\end{solution}
\end{exercise}

\begin{exercise}
BH.9.1.8. Use first step analysis to  find $N_{r} := \E X$ when $X\sim \NBin{r,p}$.
\begin{solution}
Suppose the first throw is a success, then we need $r-1$ more successes, if the first throw is a failure, we are back at `hole one'. Thus, $N_{r} = p N_{r-1}+q(1+N_{r})$. Simplifying (and using that $p/(1-q)=1$) gives $N_{r} = N_{r-1} + q/p$, which implies $N_{r} = r q/p$.
\end{solution}
\end{exercise}

\begin{exercise}
BH.9.1.9. I reason slightly differently here. Write $N_{r}$ for the number of throws required to reach $r$ heads in row. Then I need $N_{r-1}$ throws in expectation to reach the state in which there are $r-1$ heads in row. Suppose now that we are in this state, i.e.,  there are $r-1$ heads in row. Then, if I throw heads, with probability $p$, I reach the state with $r$ heads in row, and I am done. However, if I throw tails, with probability $q$, I have to start all over again.  Use this argument to derive the recursion $N_{r} = N_{r-1} + p\cdot 1 + q(1+N_{r})$.  Solve this to obtain
\begin{equation}
N_{r} = \sum_{i=1}^{r} 1/p^i.
\end{equation}
\begin{hint}
  If this is new to you, check out appendix A.4
\end{hint}
\begin{solution}
\begin{equation}
N_{r} = N_{r-1} + p\cdot 1 + q(1+N_{r}) \implies N_{r} = N_{r-1}/p + 1/p \implies N_{r} = \sum_{i=1}^{r} 1/p^i.
\end{equation}
\end{solution}
\end{exercise}

\begin{exercise}
Compute the expected outcome of a die throw (with a 6-sided die), given that the outcome is even. Introduce proper notation for random variables and events.
\begin{solution}
Let $X$ be the outcome of the die throw (note that $X$ is a random variable) and let $A$ be the event that the outcome is even. Then
\begin{equation*}
\E{X\given A} = 2 \P{X=2|A} + 4 \P{X=4|A} + 6 \P{X=6|A} = \tfrac13 \cdot (2+4+6)  = 4.
\end{equation*}
We conclude that $\E{X\given A} = 4$.
\end{solution}
\end{exercise}

\begin{exercise}
  BH.9.1.10.  Let $p_i$, $0\leq i\leq b$, be the probability to hit $b$ before $0$, with $i$ being the current position of the drunkard.
\begin{enumerate}
\item Why is $p_0=p_1/2$?
\item Why is $p_1=p_2/2$?
\item Why is $p_{b}=1$?
\item Explain the recursion $p_i=p_{i-1}/2 + p_{i+1}/2$ for $1 < i <b$?
\item Show that the previous points imply that $p_i =  \alpha i$ for $0<i<b$ for any $\alpha$ we like.
\item Combine the fact that $p_{b}=1$ with $p_{i} = \alpha i$ for all $0<i<b$ to see that $\alpha=1/b$.
\item Conclude that $p_0=1/2b$.
\end{enumerate}
\begin{hint}
  Read the gambler's ruin problem BH.2.7.3
\end{hint}

\begin{solution}
  \begin{enumerate}
    \item As in BH, condition on the first step. If the drunkard starts at zero, and makes a step to the left, he is at position $-1$. To get to $b$, with $b>0$, requires to pass $0$ again. Hence, in this case, the drunkard did not reach $b$ before 0.

    When the drunkard makes a step to the right, which occurs with probability 1/2, then the drunkard moves to position $1$. Writing $p_{1}$ for the probability to reach $b$ before $0$, it must be that $p_0 = p_1/2$.

    Written in another way: $p_0=p_{-1}\cdot 1/2 + p_1\cdot 1/2$, but $p_{-1}=0$, hence $p_0=p_1/2$.
    \item The reasoning is the same as in the  previous step. When the drunkard is in state $1$ and moves to the left, he hits 0 before $b$ so the process stops. If he moves to the right, then the process continues. Therefore $p_1=p_2/2$.
    \item If the drunkard starts in $b$, the probability to hit $b$ before $0$ is 1. (In other words, what is the probability to be in $b$ when the drunkard starts in $b$?)
    \item In some state $i$, $2\leq i < b$, condition again on whether the inebriate moves to the left or to the right.  The probability $p_{i}$ of reaching $b$ before 0 is $p_{i+1}$ when he makes a step to the right and $p_{i-1}$ when he moves to the left.  Since a step in both directions is equally likely, the equation of the problem follows.
    \item Plug in $p_i = \alpha i$ in the RHS:
      \begin{equation*}
    \frac{\alpha(i-1)}{2} + \frac{\alpha(i+1)}{2} = \alpha i - \frac{\alpha}{2} + \frac{\alpha}{2} = \alpha i = p_i
      \end{equation*}
    This shows $p_i = \alpha i$ is a solution to this recursive equation for any choice of $\alpha$.
    \item Use the boundary condition $ p_b = 1$ in the expression $p_{i}\alpha = i$ for $i=b-1$. Solving for $\alpha$ in $\alpha(b-1) = \alpha(b-2)/2+1/2$,      gives $\alpha=1/b$.
    \item Since $p_1=p-2/2 = 2/b\cdot 1/2 = 1/b$ and $p_0 = p_1 / 2$, we get that $p_{0}=1/2b$.  \end{enumerate}

  Another way you might have found $p_0$ is by noticing the following pattern when plugging in the previous values in the equation in $3$.
\begin{align*}
\textrm{As noted before } \quad & p_1 = p_2/2 \\
\textrm{Plugging the above result } \quad & p_2 = p_1/2 + p_3/2 = p_2/4 + p_3/2 \\
  \textrm{This implies } \quad & p_2 = 2/3 p_3 \\
  \textrm{Continuing substituting } \quad & p_3 = 1/3 p_3 + p_4 / 2\\
  & p_3 = 3/4 p_4 \\
  \textrm{Notice a pattern? } \quad & \dots \\
  & p_{b-1} = \frac{b-1}{b} p_b = \frac{b-1}{b}\\
  \textrm{As we already knew} \quad & p_b = 1 \\
\textrm{Now we can recursively substitute what we know to find } \quad & p_1 = \frac{1}{2} \frac{2}{3} \frac{3}{4} \dots \frac{b-1}{b} = \frac{1}{b} \\
\textrm{Then using the result from $1$} \quad & p_0 = p_1/2 = \frac{1}{2b}
\end{align*}
\end{solution}
\end{exercise}



\section{Section 9.2}
\label{sec:section-9.2}

\begin{remark} About BH. 9.2.1. This definition is subtle, and it takes time to understand.
Here is a slightly different explanation; perhaps it's useful for you.

Take some random variable $X$, say.
Then, as in Chapter 7,  we can be interested in  $\E{g(X)}$, i.e., the expectation of the rv $g(X)$.

When $Y$ is continuous we can compute $\E{Y \given X=x}$ with  the conditional CDF
\begin{align*}
\E{Y\given X=x } =\int f_{Y| X}(y | x) \d y.
\end{align*}
(For discrete rv., replace the integral by the PMF.)
Observe that this is just a function of $x$; define this function as $g(x) = \int f_{Y| X}(y | x)\d y$. And now, as before, we consider the random variable $g(X)$, and we  \emph{call this rv the conditional expectation} of $Y$ given $X$.

It is true that $X$ plays some sort of double role---first we use it in the conditioning in the definition of the function $g$, and then we plug it into  $g$ again---and this is perhaps confusing. But I finally `got  it', when I understood that $g$ can be interpreted as just some function of $x$. And then we compute $\E{g(X)}$, and so on.
\end{remark}



\begin{exercise}
BH.9.2.2. Is $\E{Y\given \1{A}}$ a number or a rv?
\begin{hint}
  Is $\1{A}$ a rv or an event?
\end{hint}
\begin{solution}
  It is a rv as the indicator function isn't crystallized, so we are conditioning on a rv ($\1{A} \sim \Bern{\P{A}}$) We could write $\E{Y\given \1{A}} = \E{Y\given A}\1{A} + \E{Y\given A^C}(1-\1{A}).$
\end{solution}
\end{exercise}


\section{Section 9.3}
\label{sec:section-9.3}

\begin{remark}
On BH.9.3.2 (Taking out what is known.) Perhaps it is easier to crystallize  $X$ into $x$. Then $g(x) = \E{h(x) Y|X} = h(x) \E{Y|X}$, because $h(x)$ is just a function. The rvs $\E{H(X) Y|X}$ and $h(X) \E{Y|X}$ are then both  equal to $g(X)$.
\end{remark}

\begin{exercise}
On BH.9.3.9. Show that $\cov{Y-\E{Y|X}, \E{Y|X}}=0$.
\begin{solution}
We have that $\E{Y-\E{Y|X}}=0$. Hence, $\E{Y-\E{Y|X}}\E X = 0$. Then define $h(X) = \E{Y|X}$ and apply BH.9.3.9 to see that $\E{(Y-\E{Y|X})h(X)} = 0$. From the definition of the covariance, $\cov{W, Z} = \E{WZ} - \E W \E Z$, we have shown that both terms are zero.
\end{solution}
\end{exercise}


\section{Section 9.4}
\label{sec:section-9.4}


\begin{exercise}
Consider a casino where, for any $a>0$, it is possible to pay $a$ euro and get a chance of $\tfrac15$ on receiving $4a$ euro and a chance of $\tfrac45$ of receiving nothing.
Adam enters the casino with $b$ euros, and bets half of his money on this gamble.
Let $X$ be the amount of money he has after the gamble.
After that, he again bets half of the money he then has (i.e.
half of $X$) on this gamble.
Let $Y$ be the amount of money he has after the second gamble.
\begin{enumerate}
\item Compute $\E{X}$.
\item Compute $\E{Y|X}$.
\item Compute $\E{Y}$.
\end{enumerate}
Explicitly mention the laws/rules you use.
\begin{solution}

1. Since Adam keeps $b/2$ and does the gamble with $a = b/2$, we have
\begin{equation*}
\E{X} = b/2 + \tfrac15 \cdot 4(b/2) + \tfrac45 \cdot 0 = 0.9 b.
\end{equation*}
2. The computation is the same as in part 1., but with $X$ instead of $b$:
\begin{equation*}
\E{Y|X} = X/2 + \tfrac15 \cdot 4(X/2) + \tfrac45 \cdot 0 = 0.9 X.
\end{equation*}
Note that the result is a random variable. \\
3. Using Adam's law (and linearity of expectation), we conclude that:
\begin{equation*}
\E{Y} = \E{\E{Y|X}} = \E{0.9X} = 0.9\E{X} = 0.81b.
\end{equation*}
In general, if Adam would do this $n$ times, the expected amount of money he has after $n$ such gambles would be $0.9^n b$. This would be very difficult to show without Adam's law!
\end{solution}
\end{exercise}


\begin{exercise}
Let $N \sim \Pois{\lambda}$, and let $X|N \sim \Bin{N, p}$, where $p \in (0,1)$ and $\lambda > 0$ are known constants.
Compute $\E{X}$ using Adam's law.
Check your answer using the chicken-egg story; with this story you can also obtain the distribution of $X$.
\begin{solution}
We have $\E{X|N} = Np$, so using Adam's law (and linearity of expectation), we conclude that $\E{X} = \E{\E{X|N}} = \E{Np} = \E{N}p = \lambda p$.

This is in accordance with $X \sim \Pois{\lambda p}$, which was shown in the chicken-egg story.

Some students reported answers like $\lambda^{2}p$. This is wrong, and can be immediately seen by checking units: the unit of $\lambda$ being 1 per time.

Others wrote $\E{X\given N= n} n p$, hence $\E X = \E{\E{X\given N}}= \E{np} = np$.

Apparently, such students are not aware of the idea that $\E{X\given N}$ is a random variable.
When this happens during the exam, you will score 0 points for that particular part of a question.

\end{solution}
\end{exercise}


\begin{exercise}
Correct? If $A$ is an event and $\1{A}$ is its indicator, then for all random variables $X$ we have $\E{X \given A} = \E{X \given \1{A}}$.
\begin{solution}
Incorrect:  $\E{X \given A}$ is a number since $A$ is an event, whereas $\E{X \given \1{A}}$ is a random variable since $\1{A}$ is a random variable. A correct statement is $\E{X \given A} = \E{X \given \1{A} = 1}$.
\end{solution}
\end{exercise}

\begin{exercise}
Correct? If $X$ and $Y$ are independent, then $\V{\E{Y \given X}} = 0$.
\begin{solution}
Correct, if  $X$ and $Y$ are independent, then $\E{Y \given X} = \E{Y}$ which is a constant (formally, a degenerate random variable).
Since the variance of a constant is 0, we conclude that $\V{\E{Y \given X}} = 0$.
\end{solution}
\end{exercise}

\begin{exercise}
Let $X \sim \Exp{\lambda}$, and let $a$ be a constant.
\begin{enumerate}
\item Compute $\E{X \given X \geq a}$ using an integral and an indicator.
\item Explain the answer using a property of the exponential distribution.
\end{enumerate}
\begin{solution}
1. We compute $\E{X \given X \geq a}$ as follows:
\begin{align*} \E{X \given X \geq a} &= \int_0^\infty y f(y|A) \d y
\\ &= \int_0^\infty y \frac{\lambda e^{-\lambda y} \1{y \geq a}}{e^{-\lambda a}} \d y
\\ &= \lambda \int_a^\infty y e^{-\lambda (y-a)} \d y
\\ &= -y e^{-\lambda (y-a)}\biggr|_a^\infty +  \int_a^\infty e^{-\lambda (y-a)} \d y
\\ &= a   - \frac1{\lambda} e^{-\lambda (y-a)}\biggr|_a^\infty   = a+\frac1\lambda.    \end{align*}

2.
The result also follows from the memoryless property, which states that conditional on the event that $X \geq a$, we have that $X-a | X \geq a \sim\Exp{\lambda}$.
\end{solution}
\end{exercise}

\begin{exercise}
A hat contains 9 fair coins and one coin that lands heads with probability 0.8. You pick a coin from the hat uniformly at random and toss it 10 times. Let $A$ be the event that you pick a fair coin, and let $X$ be the number of heads. Let $B$ be the event that the first four tosses all show heads.

\begin{enumerate}
\item Compute $\E{X \given A}$.
\item Compute $\E{X \given A^c}$.
\item Compute $\E{X}$.
\item Compute $\P{B}$.
\item Compute $\P{A \given B}$.
\item Compute $\E{X \given B}$.
\item Compute $\E{X \given B^c}$. \textit{Hint}: it is not necessary to compute $\P{A \given B^c}$.
\end{enumerate}

\begin{solution}
1. Note that $X \, |\, A \sim \Bin{10, 0.5}$, so $\E{X \given A} = 10 \cdot 0.5 = 5$. \\
2. Note that $X \, |\,  A^c \sim \Bin{10, 0.8}$, so $\E{X \given A^c} = 10 \cdot 0.8 = 8$. \\
3. By LOTE we have $\E{X} = \P{A}\E{X \given A} +\P{A^c} \E{X \given A^c}  = 0.9 \cdot 5 + 0.1\cdot 8 = 5.3$. \\
4. Note that  $\P{B \given A}  = 0.5^4$ and $\P{B \given A^c}  = 0.8^4$.
By LOTP we have
\begin{equation*}
\P{B} = \P{A}\P{B \given A} +\P{A^c} \P{B \given A^c}  = 0.9 \cdot 5 + 0.1\cdot 8 = 0.09721.
\end{equation*}
5. By Bayes' rule $\P{A \given B} = \frac{\P{B \given A}\P{A}}{\P{B}} \approx 0.57864$. \\
6. Note that $\E{X \given A, B} = 4 + 6 \cdot 0.5 = 7$ and $\E{X \given A^c, B} = 4 + 6 \cdot 0.8 = 8.8$. By LOTP with extra conditioning we have
\begin{equation*}
\P{X \given B} = \P{A \given B}\E{X \given A, B} + \P{A^c \given B}\E{X \given A^c, B} \approx 7.75844.
\end{equation*}
7. By LOTE we have $\P{B}\E{X \given B} +\P{B^c} \E{X \given B^c}  = \E{X} = 5.3$. We know $\P{B}$ and $\E{X \given B}$, so solving this for $\E{X \given B^c}$ yields $\E{X \given B^c} \approx 5.035$.

One or more students wrote the LOTE as $\E X = \sum_{Y} \E{X\given Y} \P{Y}$. This is wrong, as you cannot sum over a rv. This is correct: $\E{X} = \sum_{y} \E{X\given Y=y} \P{Y=y}$, so sum over the \emph{outcomes} of a rv.

\end{solution}
\end{exercise}


\begin{exercise}
Consider random variables $X, Y \in [0,1]^2$ with joint PDF $f_{X,Y}(x,y) = 2 \1{x \leq y}$.

Determine $\E{Y \given X}$ and $\E{X \given Y}$.
\begin{solution}
The marginal density of $X$ is given by $f_X(x) = 2(1-x)$.

So the conditional density is given by $f_{Y|X}(y|x) = \frac{f_{X,Y}(x,y)}{f_X(x)} = \frac{\1{x \leq y}}{1-x}$. Hence,
\begin{equation*}
\E{Y \given X = x} = \int_0^1 y \frac{\1{x \leq y}}{1-x} \d y  = \frac1{1-x}  \int_x^1 y \d y = \frac1{1-x} \left[\tfrac12y^2\right]_x^1 = \frac{\tfrac12\left(1-x^2\right)}{1-x} =  \tfrac12 \left(1+x\right) .
\end{equation*}
We conclude that $\E{Y \given X} = \tfrac12(1+X)$.


The marginal density of $Y$ is given by $f_Y(y) = 2y$.

So the conditional density is given by $f_{X|Y}(x|y) = \frac{f_{X,Y}(x,y)}{f_Y(y)} = \frac{\1{x \leq y}}{y}$. So
\begin{equation*}
\E{X \given Y = y} = \int_0^1 x \frac{\1{x \leq y}}{y} \d x  = \frac1{y}   \int_0^y x \d x = \tfrac12 y.
\end{equation*}
We conclude that $\E{X \given Y} = \tfrac12Y$.

Some students wrote for instance $\E{X\given Y} = y/2$.
Apparently, such students are not aware of the idea that $\E{X\given N}$ is a random variable.
When this happens during the exam, you will score 0 points for that particular part of a question.

\end{solution}
\end{exercise}





\begin{exercise}
Prove that $\E{X \given X \geq a} > \E{X}$ for any $a$ with $0 < \P{X \geq a} < 1$.
\begin{solution}
Note that $\E{X \given X \geq a} \geq a > \E{X \given X < a}$. By LOTE:
\begin{align*}
\E{X} &= \P{X \geq a}  \E{X \given X \geq a} + \P{X <a}  \E{X \given X < a}
\\  &< \P{X \geq a}  \E{X \given X \geq a} + \P{X <a}  \E{X \given X \geq a}
\\  &= \E{X \given X \geq a},
\end{align*}
where the inequality is strict since $ \P{X <a} > 0$.
\end{solution}
\end{exercise}




\begin{exercise}
Let $N \sim \Pois{\lambda}$ and let  $X|N \sim \Bin{N, p}$, where $p \in (0,1)$ and $\lambda > 0$ are known constants. Find $\E{N \given X}$.
\begin{hint}
  For a smart argument, use the chicken-egg story.
  Recall that the number of hatched eggs and the number of unhatched eggs are independent (since $N \sim \Pois{\lambda}$); i.e.
  $N-X$ and $X$ are independent.
\end{hint}
\begin{solution}
With the hint,
\begin{equation*} \E{N \given X} = \E{N-X \given X} + \E{X \given X} = \E{N-X} + X = \lambda(1-p) + X. \end{equation*}
As a check, $\E{ \E{N \given X}} = \E{\lambda(1-p) + X} = \lambda(1-p)  + \lambda p = \lambda  = \E{N}$.

Here is straightforward computation.
You should check each and every step as they are based on pattern recognition.
\begin{align}
  \label{eq:22}
\E{N \given X=k}
&= \sum_{n=k}^{\infty} n \P{N=n \given X=k } \\
&= \frac{1}{\P{X=k}} \sum_{n=k}^{\infty} n e^{-\lambda}\frac{\lambda^{n}}{n!} {n \choose k} p^{k}(1-p)^{n-k} \\
&= \frac{1}{\P{X=k}}\sum_{n=k}^{\infty} n e^{-\lambda}\frac{1}{n!} \frac{n!}{k!(n-k)!}(\lambda p)^{k}(\lambda(1-p))^{n-k} \\
&= \frac{e^{-\lambda p} (\lambda p)^{k}/k!}{\P{X=k}}\sum_{n=k}^{\infty} n e^{-\lambda(1-p)}\frac{1}{(n-k)!}(\lambda(1-p))^{n-k} \\
&= \sum_{n=k}^{\infty} n e^{-\lambda(1-p)}\frac{1}{(n-k)!}(\lambda(1-p))^{n-k} \\
&= \sum_{n=0}^{\infty} (n+k) e^{-\lambda(1-p)}\frac{1}{n!}(\lambda(1-p))^{n} \\
&= k  + \sum_{n=0}^{\infty} n e^{-\lambda(1-p)}\frac{1}{n!}(\lambda(1-p))^{n} \\
&= k  + \lambda (1-p).
\end{align}
Hence, $\E{N\given X}= \lambda(1-p) + X$. Since $\E X = \lambda p$, we get $\E N = \lambda$ with Adam's law, as above.
\end{solution}
\end{exercise}

\section{Section 9.5}
\label{sec:section-9.5}

\begin{exercise}
BH.9.5.1. Is $\V{Y|X}= \V{\E{Y|X}}$?
\begin{hint}
\end{hint}
\begin{solution}
\end{solution}
\end{exercise}



\begin{exercise}
Use Eve's law to show that $\V Y \geq \V{\E{Y\given X}}$.
\begin{solution}
By Eve's law,
\begin{align}
    \V Y = \E{\V{Y\given X}} + \V{\E{Y\given X}} \geq \V{\E{Y\given X}},
\end{align}
since $\V{Y\given X} \geq 0$ for all $X$, which implies that $\E{\V{Y\given X}} \geq 0$.
\end{solution}
\end{exercise}


\begin{exercise}
Let $Z\sim \mathcal{N}(\mu, \sigma^2)$ and $Y=\sqrt{Z}+Z^2.$ Find $\V{Y|Z}$.
\begin{solution}
Conditional on $Z$, $Y$ is a constant, and the variance of a constant is 0. Hence, $\V{Y|Z} = 0$.
\end{solution}
\end{exercise}


\begin{exercise}
Correct? $\V{Y}=\V{Y|A}\P{A}+\V{Y|A^c}\P{A^c}$ for any random variable $Y$ and event $A$.

\begin{solution}
Incorrect. Counterexample: Let $Y\sim$ Bern(1/2) and $A$ be the event $Y=0$. then Var($Y|A$) and Var($Y|A^c$) are both 0, but Var($Y$)=1/4.
\end{solution}
\end{exercise}


\begin{exercise}
Let $X, Y$ be random variables. Explain the difference between $\V{Y|X}$ and $\V{Y|X=x}$.

\begin{solution}
$\V{Y|X}$ is a random variable, but $\V{Y|X=x}$ is a constant.
\end{solution}
\end{exercise}


\begin{exercise}
Show that $\E{(Y - \E{Y |X})^2|X} = \E{Y^2|X} - (\E{Y |X})^2$.

\begin{solution}
Define $g(X) = \E{Y|X}$. Then,
\begin{align}
    \E{(Y - \E{Y |X})^2|X}&= \E{(Y - g(X))^2|X}\\
    &=\E{Y^2-2Yg(X)+g(X)^2|X}\\
    &=\E{Y^2|X}-2\E{Yg(X)|X}+\E{g(X)^2|X}\\
    &=\E{Y^2|X}-2g(X)\E{Y|X}+g(X)^2\\
    &=\E{Y^2|X}-2g(X)^2+g(X)^2\\
    &=\E{Y^2|X}-(\E{Y |X})^2
\end{align}
\end{solution}
\end{exercise}


\begin{exercise}
Let $X\sim \mathcal{N}(\mu,\sigma^2)$ and $W|X \sim \mathcal{N}(0,X^2)$. Find $\V{W}.$
\begin{solution}
Using Eve's Law we have
\begin{align}
    \V{W} = \V{\E{W|X}}+\E{\V{W|X}} =\V{0} + \E{X^2} = 0+  \mu^2 + \sigma^2 = \mu^2 + \sigma^2.
\end{align}

\end{solution}
\end{exercise}


\input{trailer.tex}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "study-guide.tex"
%%% End:
